{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1c8e077",
   "metadata": {},
   "source": [
    "## Fine-tune Minerva3B-base \n",
    "To fine-tune Minerva3B-base we make use of the **unsloth** library. \n",
    "**NOTE**: The notebook was prepared to run on Google Colab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b6af56",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import os, re\n",
    "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
    "    !pip install unsloth\n",
    "else:\n",
    "    # Do this only in Colab notebooks! Otherwise use pip install unsloth\n",
    "    import torch; v = re.match(r\"[0-9\\.]{3,}\", str(torch.__version__)).group(0)\n",
    "    xformers = \"xformers==\" + (\"0.0.32.post2\" if v == \"2.8.0\" else \"0.0.29.post3\")\n",
    "    !pip install --no-deps bitsandbytes accelerate {xformers} peft trl triton cut_cross_entropy unsloth_zoo\n",
    "    !pip install sentencepiece protobuf \"datasets>=3.4.1,<4.0.0\" \"huggingface_hub>=0.34.0\" hf_transfer\n",
    "    !pip install --no-deps unsloth\n",
    "!pip install transformers==4.55.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcceb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "from transformers import TextStreamer\n",
    "import json\n",
    "from huggingface_hub import HfApi, login\n",
    "import torch\n",
    "import os\n",
    "from google.colab import drive\n",
    "from datasets import load_from_disk#, load_dataset\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from trl import SFTTrainer, SFTConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff85ba8c",
   "metadata": {},
   "source": [
    "Mount drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971cd278",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2ca851",
   "metadata": {},
   "source": [
    "To import `Minerva3B-base` you'll need to generate the token and log in to hugging-face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f53de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import userdata\n",
    "from huggingface_hub import login\n",
    "hf_token = userdata.get('HF_TOKEN')\n",
    "login(token=hf_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09df997",
   "metadata": {},
   "source": [
    "#### Unsloth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f738cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"sapienzanlp/Minerva-3B-base-v1.0\",\n",
    "    max_seq_length = 1024,\n",
    "    load_in_4bit = True,\n",
    "    load_in_8bit = False,\n",
    "    full_finetuning = False,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
